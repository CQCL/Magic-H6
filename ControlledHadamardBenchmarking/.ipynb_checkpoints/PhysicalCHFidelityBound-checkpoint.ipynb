{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f118e3-682f-4a13-bd34-3b2fd6cb3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Quantinuum (www.quantinuum.com)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d50cb-3771-4a9a-a730-cbf6d359255c",
   "metadata": {},
   "source": [
    "### Use CVXPY to upper bound process fidelity subject to known output state fidelities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6954cbc0-13c7-4b8f-9c05-03d4a38eaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cca6859-999f-4f51-8ed4-fbff8c0ff100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum process fidelity is  0.9987445954\n"
     ]
    }
   ],
   "source": [
    "#First, we compute X_tar, the Choi matrix of the target gate\n",
    "d = 4\n",
    "U_tar = np.array([[1,0,0,0],[0,1,0,0],[0,0,np.sqrt(1/2),np.sqrt(1/2)],[0,0,np.sqrt(1/2),-np.sqrt(1/2)]]) # CH\n",
    "phi_ME = np.zeros(d**2)\n",
    "for j in range(d):\n",
    "    phi_ME = phi_ME + np.kron(np.eye(1,d,j), np.eye(1,d,j))/np.sqrt(d)\n",
    "rho_ME = np.outer(phi_ME, np.conj(phi_ME))\n",
    "X_tar = np.kron(np.identity(d), U_tar) @ rho_ME @ np.kron(np.identity(d), np.conj(U_tar).T)\n",
    "\n",
    "# basis states\n",
    "state_dict = {'0':np.array([1,0]), '1':np.array([0,1]), '+':np.array([1,1])/np.sqrt(2), '-':np.array([1,-1])/np.sqrt(2), 'H':np.array([np.cos(np.pi/8), np.sin(np.pi/8)]), 'M':np.array([-np.sin(np.pi/8), np.cos(np.pi/8)]), 'i':np.array([1,1j])/np.sqrt(2), 'j':np.array([1,-1j])/np.sqrt(2)}\n",
    "\n",
    "A = [] # constraint matrices\n",
    "b = [] # constraint values\n",
    "\n",
    "#  output state fidelities from physical CH experiment\n",
    "fid_dict = {\n",
    "    '00':1 - 0.00369,\n",
    "    '01':1 - 0.00411,\n",
    "    '10':1 - 0.00311,\n",
    "    '11':1 - 0.00352,\n",
    "    '+H':1 - 0.00397, \n",
    "    '+M': 1 - 0.00424,\n",
    "    '-H': 1- 0.00352,\n",
    "    '-M': 1 - 0.0038,\n",
    "    '1+': 1 - 0.00329,\n",
    "    '0-': 1 - 0.00397,\n",
    "    '0+': 1 - 0.00374,\n",
    "    '1-': 1 - 0.00385,\n",
    "}\n",
    "\n",
    "uncertainty_dict = {\n",
    "    '00': 0.00019209372712298544,\n",
    "    '01': 0.00028982753492378874,\n",
    "    '10': 0.00017635192088548396,\n",
    "    '11': 0.0001876166303929372,\n",
    "    '+H': 0.00019924858845171275,\n",
    "    '+M': 0.00020591260281974002,\n",
    "    '-H': 0.0001876166303929372,\n",
    "    '-M': 0.00019493588689617925,\n",
    "    '1+': 0.00018138357147217052,\n",
    "    '0-': 0.00019924858845171275,\n",
    "    '0+': 0.00019339079605813715,\n",
    "    '1-': 0.00019621416870348583,\n",
    "}\n",
    "\n",
    "# example of output state fidelities\n",
    "out_dict = {\n",
    "    '00': '00',\n",
    "    '01': '01',\n",
    "    '10': '1+',\n",
    "    '11': '1-',\n",
    "    '+H': '+H',\n",
    "    '+M': '-M',\n",
    "    '-H': '-H',\n",
    "    '-M': '+M',\n",
    "    '1+': '10',\n",
    "    '0-': '01',\n",
    "    '0+': '0+',\n",
    "    '1-': '11',\n",
    "}\n",
    "\n",
    "\n",
    "# Forming the measurement POVMS for the 0,1,+,-,H+,H- states. The measurement error is .001316 for all states and .003656 for its orthogonal complement.\n",
    "# This is because we rotate the expected output states to |0> before measuring in all experiments to minimize measurement error.\n",
    "povm_dict = {}\n",
    "psi = state_dict['0']\n",
    "psi_orth = state_dict['1']\n",
    "\n",
    "povm0 = (1 - 0.001316)*np.outer(psi, np.conj(psi)) + (.003656)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "povm1 = (.003656)*np.outer(psi, np.conj(psi)) + (1 - 0.001316)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "povm_dict['0'] = povm0\n",
    "povm_dict['1'] = povm1\n",
    "\n",
    "psi = state_dict['+']\n",
    "psi_orth = state_dict['-']\n",
    "povm_plus = (1 - 0.001316)*np.outer(psi, np.conj(psi)) + (.003656)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "povm_minus = (.003656)*np.outer(psi, np.conj(psi)) + (1 - 0.001316)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "\n",
    "povm_dict['+'] = povm_plus\n",
    "povm_dict['-'] = povm_minus\n",
    "\n",
    "\n",
    "psi = state_dict['H']\n",
    "psi_orth = state_dict['M']\n",
    "povm_H = (1 - 0.001316)*np.outer(psi, np.conj(psi)) + (.003656)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "povm_M = (.003656)*np.outer(psi, np.conj(psi)) + (1 - 0.001316)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "\n",
    "povm_dict['H'] = povm_H\n",
    "povm_dict['M'] = povm_M\n",
    "\n",
    "\n",
    "for state in fid_dict:\n",
    "    \n",
    "    # ZZ or XX basis input states\n",
    "    psi = np.kron(state_dict[state[0]], state_dict[state[1]])\n",
    "    rho = np.outer(psi, np.conj(psi))\n",
    "\n",
    "    M = np.kron(povm_dict[out_dict[state][0]],povm_dict[out_dict[state][1]])\n",
    "\n",
    "    #M = U_tar @ rho @ np.conj(U_tar.T) # measurement operator\n",
    "    A.append(np.kron(rho.T,M))\n",
    "    b.append(fid_dict[state])\n",
    "        \n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "# Create a symmetric matrix variable.\n",
    "X = cp.Variable((d**2,d**2), hermitian=True)\n",
    "# The operator >> denotes matrix inequality.\n",
    "constraints = [X >> 0]\n",
    "\n",
    "# constraints on output state fidelities\n",
    "constraints += [d*cp.real(cp.trace(A[k] @ X)) <= b[k] for k in range(len(A))]\n",
    "\n",
    "# add partial trace constraints\n",
    "for i in range(d):\n",
    "    for j in range(d):\n",
    "        B_ij = np.kron(np.outer(np.eye(1,d,i), np.eye(1,d,j)),np.identity(d))\n",
    "        if i == j:\n",
    "            constraints += [d*cp.real(cp.trace(B_ij @ X)) == 1.0]\n",
    "        else:\n",
    "            constraints += [d*cp.real(cp.trace(B_ij @ X)) == 0.0]\n",
    "\n",
    "\n",
    "# setup and solve problem\n",
    "prob = cp.Problem(cp.Maximize(cp.real(cp.trace(X_tar @ X))),\n",
    "                  constraints)\n",
    "\n",
    "F_lo = prob.solve()\n",
    "\n",
    "\n",
    "print(\"Maximum process fidelity is \", round(F_lo,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac628eed-3aa6-46b0-8f30-936146894f81",
   "metadata": {},
   "source": [
    "Now we compute the derivative of the fidelity with respect to each of the state fidelities. For each state fidelity, we approximate the derivative by taking the finite quotient of the process fidelity at the endpoints of the state fidelity confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470ea7a2-1e5e-402a-a7c3-e82b4ef2693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_dict = {}\n",
    "for state in fid_dict.keys():\n",
    "    fid_dict_new = fid_dict.copy()\n",
    "    fid_dict_new[state] = fid_dict[state] + uncertainty_dict[state]\n",
    "    \n",
    "    b = [] # constraint values\n",
    "    for state2 in fid_dict:\n",
    "        b.append(fid_dict_new[state2])\n",
    "            \n",
    "    \n",
    "    # Define and solve the CVXPY problem.\n",
    "    # Create a symmetric matrix variable.\n",
    "    X = cp.Variable((d**2,d**2), hermitian=True)\n",
    "    # The operator >> denotes matrix inequality.\n",
    "    constraints = [X >> 0]\n",
    "    \n",
    "    # constraints on output state fidelities\n",
    "    constraints += [d*cp.real(cp.trace(A[k] @ X)) <= b[k] for k in range(len(A))]\n",
    "    \n",
    "    # add partial trace constraints\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            B_ij = np.kron(np.outer(np.eye(1,d,i), np.eye(1,d,j)),np.identity(d))\n",
    "            if i == j:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 1.0]\n",
    "            else:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 0.0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # setup and solve problem\n",
    "    prob = cp.Problem(cp.Maximize(cp.real(cp.trace(X_tar @ X))),\n",
    "                      constraints)\n",
    "    \n",
    "    F_lo_plus = prob.solve()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fid_dict_new[state] = fid_dict[state] - uncertainty_dict[state]\n",
    "    b = [] # constraint values\n",
    "    for state2 in fid_dict_new:\n",
    "        b.append(fid_dict_new[state2])\n",
    "            \n",
    "    \n",
    "    # Define and solve the CVXPY problem.\n",
    "    # Create a symmetric matrix variable.\n",
    "    X = cp.Variable((d**2,d**2), hermitian=True)\n",
    "    # The operator >> denotes matrix inequality.\n",
    "    constraints = [X >> 0]\n",
    "    \n",
    "    # constraints on output state fidelities\n",
    "    constraints += [d*cp.real(cp.trace(A[k] @ X)) <= b[k] for k in range(len(A))]\n",
    "    \n",
    "    # add partial trace constraints\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            B_ij = np.kron(np.outer(np.eye(1,d,i), np.eye(1,d,j)),np.identity(d))\n",
    "            if i == j:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 1.0]\n",
    "            else:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 0.0]\n",
    "    \n",
    "    \n",
    "    # setup and solve problem\n",
    "    prob = cp.Problem(cp.Maximize(cp.real(cp.trace(X_tar @ X))),\n",
    "                      constraints)\n",
    "    \n",
    "    F_lo_minus = prob.solve()\n",
    "    derivative_dict[state] = abs((F_lo_plus - F_lo_minus)/(2*uncertainty_dict[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65cda648-31ca-4774-bf4b-f70d0b05988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 0.0008725164503780878,\n",
       " '01': 0.06001580491222345,\n",
       " '10': 0.006362823891375271,\n",
       " '11': 0.0014689655789759484,\n",
       " '+H': 0.2559034763322076,\n",
       " '+M': 0.23788810558435255,\n",
       " '-H': 0.2526300268798393,\n",
       " '-M': 0.2686313173014511,\n",
       " '1+': 0.008533591009703126,\n",
       " '0-': 0.002606224220563543,\n",
       " '0+': 0.004172454896104167,\n",
       " '1-': 0.02080329673974337}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivative_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d18ae0-60fa-476d-8daa-3f63932e4f23",
   "metadata": {},
   "source": [
    "Now we compute how the fidelity bound changes with respect to the measurement error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ddff1f-b397-4b1d-9c57-74a81cb4dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fidelity_bound(meas0_err, meas1_err):\n",
    "    d = 4\n",
    "    U_tar = np.array([[1,0,0,0],[0,1,0,0],[0,0,np.sqrt(1/2),np.sqrt(1/2)],[0,0,np.sqrt(1/2),-np.sqrt(1/2)]]) # CH\n",
    "    phi_ME = np.zeros(d**2)\n",
    "    for j in range(d):\n",
    "        phi_ME = phi_ME + np.kron(np.eye(1,d,j), np.eye(1,d,j))/np.sqrt(d)\n",
    "    rho_ME = np.outer(phi_ME, np.conj(phi_ME))\n",
    "    X_tar = np.kron(np.identity(d), U_tar) @ rho_ME @ np.kron(np.identity(d), np.conj(U_tar).T)\n",
    "    \n",
    "    # basis states\n",
    "    state_dict = {'0':np.array([1,0]), '1':np.array([0,1]), '+':np.array([1,1])/np.sqrt(2), '-':np.array([1,-1])/np.sqrt(2), 'H':np.array([np.cos(np.pi/8), np.sin(np.pi/8)]), 'M':np.array([-np.sin(np.pi/8), np.cos(np.pi/8)]), 'i':np.array([1,1j])/np.sqrt(2), 'j':np.array([1,-1j])/np.sqrt(2)}\n",
    "    \n",
    "    A = [] # constraint matrices\n",
    "    b = [] # constraint values\n",
    "    \n",
    "    #  output state fidelities from physical CH experiment\n",
    "    fid_dict = {\n",
    "        '00':1 - 0.00369,\n",
    "        '01':1 - 0.00411,\n",
    "        '10':1 - 0.00311,\n",
    "        '11':1 - 0.00352,\n",
    "        '+H':1 - 0.00397, \n",
    "        '+M': 1 - 0.00424,\n",
    "        '-H': 1- 0.00352,\n",
    "        '-M': 1 - 0.0038,\n",
    "        '1+': 1 - 0.00329,\n",
    "        '0-': 1 - 0.00397,\n",
    "        '0+': 1 - 0.00374,\n",
    "        '1-': 1 - 0.00385,\n",
    "    }\n",
    "    \n",
    "    uncertainty_dict = {\n",
    "        '00': 0.00019209372712298544,\n",
    "        '01': 0.00028982753492378874,\n",
    "        '10': 0.00017635192088548396,\n",
    "        '11': 0.0001876166303929372,\n",
    "        '+H': 0.00019924858845171275,\n",
    "        '+M': 0.00020591260281974002,\n",
    "        '-H': 0.0001876166303929372,\n",
    "        '-M': 0.00019493588689617925,\n",
    "        '1+': 0.00018138357147217052,\n",
    "        '0-': 0.00019924858845171275,\n",
    "        '0+': 0.00019339079605813715,\n",
    "        '1-': 0.00019621416870348583,\n",
    "    }\n",
    "    \n",
    "    # example of output state fidelities\n",
    "    out_dict = {\n",
    "        '00': '00',\n",
    "        '01': '01',\n",
    "        '10': '1+',\n",
    "        '11': '1-',\n",
    "        '+H': '+H',\n",
    "        '+M': '-M',\n",
    "        '-H': '-H',\n",
    "        '-M': '+M',\n",
    "        '1+': '10',\n",
    "        '0-': '01',\n",
    "        '0+': '0+',\n",
    "        '1-': '11',\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    povm_dict = {}\n",
    "    psi = state_dict['0']\n",
    "    psi_orth = state_dict['1']\n",
    "    \n",
    "    povm0 = (1 - meas0_err)*np.outer(psi, np.conj(psi)) + (meas1_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    povm1 = (meas1_err)*np.outer(psi, np.conj(psi)) + (1 - meas0_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    povm_dict['0'] = povm0\n",
    "    povm_dict['1'] = povm1\n",
    "    \n",
    "    psi = state_dict['+']\n",
    "    psi_orth = state_dict['-']\n",
    "    povm_plus = (1 - meas0_err)*np.outer(psi, np.conj(psi)) + (meas1_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    povm_minus = (meas1_err)*np.outer(psi, np.conj(psi)) + (1 - meas0_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    \n",
    "    povm_dict['+'] = povm_plus\n",
    "    povm_dict['-'] = povm_minus\n",
    "    \n",
    "    \n",
    "    psi = state_dict['H']\n",
    "    psi_orth = state_dict['M']\n",
    "    povm_H = (1 - meas0_err)*np.outer(psi, np.conj(psi)) + (meas1_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    povm_M = (meas1_err)*np.outer(psi, np.conj(psi)) + (1 - meas0_err)*np.outer(psi_orth, np.conj(psi_orth))\n",
    "    \n",
    "    povm_dict['H'] = povm_H\n",
    "    povm_dict['M'] = povm_M\n",
    "    \n",
    "    \n",
    "    for state in fid_dict:\n",
    "        \n",
    "        # ZZ or XX basis input states\n",
    "        psi = np.kron(state_dict[state[0]], state_dict[state[1]])\n",
    "        rho = np.outer(psi, np.conj(psi))\n",
    "    \n",
    "        M = np.kron(povm_dict[out_dict[state][0]],povm_dict[out_dict[state][1]])\n",
    "    \n",
    "        #M = U_tar @ rho @ np.conj(U_tar.T) # measurement operator\n",
    "        A.append(np.kron(rho.T,M))\n",
    "        b.append(fid_dict[state])\n",
    "            \n",
    "    \n",
    "    # Define and solve the CVXPY problem.\n",
    "    # Create a symmetric matrix variable.\n",
    "    X = cp.Variable((d**2,d**2), hermitian=True)\n",
    "    # The operator >> denotes matrix inequality.\n",
    "    constraints = [X >> 0]\n",
    "    \n",
    "    # constraints on output state fidelities\n",
    "    constraints += [d*cp.real(cp.trace(A[k] @ X)) <= b[k] for k in range(len(A))]\n",
    "    \n",
    "    # add partial trace constraints\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            B_ij = np.kron(np.outer(np.eye(1,d,i), np.eye(1,d,j)),np.identity(d))\n",
    "            if i == j:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 1.0]\n",
    "            else:\n",
    "                constraints += [d*cp.real(cp.trace(B_ij @ X)) == 0.0]\n",
    "    \n",
    "    \n",
    "    # setup and solve problem\n",
    "    prob = cp.Problem(cp.Maximize(cp.real(cp.trace(X_tar @ X))),\n",
    "                      constraints)\n",
    "    \n",
    "    return(prob.solve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aafc4df-f41c-479f-9ffe-aa69ed159073",
   "metadata": {},
   "source": [
    "Now we add the derivatives of the process fidelity with respect to the measurement error to our list. Again, these derivatives are computed by taking the difference at either endpoint of the confidence interval for the measurement error of 0 and 1. These confidence intervals have half-lengths of 3e-5 and 6e-5 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2d256f5-375d-432f-b152-92ec7d9033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_dict['meas0_err'] = (compute_fidelity_bound(.001316 + .000034, 0.003656) - compute_fidelity_bound(.001316 - .000034, 0.003656))/(2*.000034)\n",
    "derivative_dict['meas1_err'] = (compute_fidelity_bound(.001316, 0.003656 + .000056) - compute_fidelity_bound(.001316, 0.003656  - .000056))/(2*.000056)\n",
    "uncertainty_dict['meas0_err'] = .000034\n",
    "uncertainty_dict['meas1_err'] = .000056"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfc8f3-8c30-4c9c-b61a-d0d7ae3501d2",
   "metadata": {},
   "source": [
    "We can view the derivative of the process fidelity with respect to each observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3dd6e51-28d9-48a0-a7f0-d8027e4fc3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 0.0008725164503780878,\n",
       " '01': 0.06001580491222345,\n",
       " '10': 0.006362823891375271,\n",
       " '11': 0.0014689655789759484,\n",
       " '+H': 0.2559034763322076,\n",
       " '+M': 0.23788810558435255,\n",
       " '-H': 0.2526300268798393,\n",
       " '-M': 0.2686313173014511,\n",
       " '1+': 0.008533591009703126,\n",
       " '0-': 0.002606224220563543,\n",
       " '0+': 0.004172454896104167,\n",
       " '1-': 0.02080329673974337,\n",
       " 'meas0_err': 2.002065643617307,\n",
       " 'meas1_err': -0.008606171091250583}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivative_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db19fdb-3351-49c8-b2b8-e27aaf5df2bd",
   "metadata": {},
   "source": [
    "Using these derivatives, we can apply the propagation of uncertainty rule to estimate the total uncertainty of the process fidelity coming from each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e740e074-d6b0-445f-8353-c10d54b81abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4945672955250457e-08\n",
      "0.0001222524967239952\n"
     ]
    }
   ],
   "source": [
    "variance = 0\n",
    "import math\n",
    "for parameter in derivative_dict.keys():\n",
    "    variance += (derivative_dict[parameter]*uncertainty_dict[parameter])**2\n",
    "print(variance)\n",
    "st_dev = math.sqrt(variance)\n",
    "print(st_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e06c8c-dc28-4a32-b313-d8a58eee9c66",
   "metadata": {},
   "source": [
    "We convert from process fidelity to average fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b36088f-fde6-48aa-8c99-826c96e28521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average infidelity lower bound:  0.0010043237131623917\n",
      "standard deviation of the average infidelity:  9.780199737919617e-05\n"
     ]
    }
   ],
   "source": [
    "print('average infidelity lower bound: ', 1- ((4*(F_lo) + 1)/(4+1)))\n",
    "print('standard deviation of the average infidelity: ', (4/5)*(st_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6b9d7-a60d-47be-94da-8960a6f05e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
